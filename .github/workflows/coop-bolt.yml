name: "Coop (Bolt Food) – Auto category crawl → CSV/DB"

on:
  workflow_dispatch:
    inputs:
      city_path:
        description: "Bolt city path (from URL after /en-US/, e.g. 2-tartu)"
        required: false
        default: "2-tartu"
      stores_multiline:
        description: "Store display names (one per line). Leave empty to use the 3 Tartu Maksimarkets."
        required: false
        default: |
          Lõunakeskuse COOP Maksimarket
          Eedeni COOP Maksimarket
          Kvartali COOP Maksimarket
      headless:
        description: "Headless Playwright (1/0)"
        required: false
        default: "1"
      req_delay:
        description: "Delay between steps (sec)"
        required: false
        default: "0.25"
      upsert_db:
        description: "Upsert into Postgres (1=yes, 0=just CSV)"
        required: false
        default: "1"
      categories_dir:
        description: "Optional: base dir for per-store category files (uses {dir}/{city}/{slug}.txt if present)"
        required: false
        default: "data/bolt"
  schedule:
    - cron: "0 */2 * * *" # every 2 hours

concurrency:
  group: coop-bolt-crawl
  cancel-in-progress: false

jobs:
  crawl-bolt:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install playwright==1.47.0 selectolax psycopg[binary] tenacity
          python -m playwright install --with-deps chromium

      - name: Crawl each store (array-based, preserves spaces/newlines)
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          CITY_PATH: ${{ inputs.city_path }}
          HEADLESS: ${{ inputs.headless }}
          REQ_DELAY: ${{ inputs.req_delay }}
          UPSERT_DB: ${{ inputs.upsert_db }}
          CATEGORIES_DIR: ${{ inputs.categories_dir }}
        shell: bash
        run: |
          set -euo pipefail

          # Safe defaults for scheduled runs (inputs can be empty)
          CITY_PATH="${CITY_PATH:-2-tartu}"
          HEADLESS="${HEADLESS:-1}"
          REQ_DELAY="${REQ_DELAY:-0.25}"
          UPSERT_DB="${UPSERT_DB:-1}"
          CATEGORIES_DIR="${CATEGORIES_DIR:-data/bolt}"

          # Build STORES array
          if [ -z "${{ inputs.stores_multiline }}" ]; then
            # Default three Tartu stores
            STORES=(
              "Lõunakeskuse COOP Maksimarket"
              "Eedeni COOP Maksimarket"
              "Kvartali COOP Maksimarket"
            )
          else
            # Normalize CRLF and split on newlines into array
            mapfile -t STORES < <(printf "%s" "${{ inputs.stores_multiline }}" | tr -d '\r')
          fi

          echo "Stores to crawl:"
          printf ' - %s\n' "${STORES[@]}"

          mkdir -p out
          for STORE in "${STORES[@]}"; do
            [ -z "$STORE" ] && continue
            SAFE_NAME="$(echo "$STORE" | tr ' ' '_' | tr -dc '[:alnum:]_')"
            echo "==> Crawling: $STORE (city=${CITY_PATH}, headless=${HEADLESS}, delay=${REQ_DELAY}, upsert=${UPSERT_DB})"
            python scripts/bolt_crawler.py \
              --city "${CITY_PATH}" \
              --store "${STORE}" \
              --headless "${HEADLESS}" \
              --req-delay "${REQ_DELAY}" \
              --upsert-db "${UPSERT_DB}" \
              --categories-dir "${CATEGORIES_DIR}" \
              --out "out/coop_bolt_${CITY_PATH}_${SAFE_NAME}.csv"
          done

      - name: Upload CSV artifacts
        uses: actions/upload-artifact@v4
        with:
          name: "coop-bolt-csv"
          path: out/*.csv
          if-no-files-found: warn
