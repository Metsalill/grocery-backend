name: Coop Bolt scrape + DB ingest

on:
  workflow_dispatch: {}
  schedule:
    - cron: "25 */12 * * *"

concurrency:
  group: coop-bolt
  cancel-in-progress: true

jobs:
  scrape-bolt:
    runs-on: ubuntu-latest
    timeout-minutes: 25

    strategy:
      fail-fast: false
      matrix:
        include:
          - city: tartu
            city_dir: 2-tartu
            venue_slug: kvartali-coop-maksimarket
            store_id: 559
            out: out/bolt_kvartali.csv
          - city: tartu
            city_dir: 2-tartu
            venue_slug: lounakeskuse-coop-maksimarket
            store_id: 561
            out: out/bolt_lounakeskuse.csv
          - city: tartu
            city_dir: 2-tartu
            venue_slug: eedeni-coop-maksimarket
            store_id: 560
            out: out/bolt_eedeni.csv

    env:
      DATABASE_URL: ${{ secrets.RW_DATABASE_URL }}
      PYTHONUNBUFFERED: "1"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install crawler deps
        run: |
          python -m pip install --upgrade pip
          pip install asyncpg psycopg[binary] requests beautifulsoup4 selectolax httpx lxml pydantic python-dateutil playwright
          python -m playwright install --with-deps chromium

      - name: Run Bolt crawler + ingest
        run: |
          set -euo pipefail
          mkdir -p out
          python scripts/bolt_crawler.py \
            --city "${{ matrix.city }}" \
            --venue-slug "${{ matrix.venue_slug }}" \
            --categories-file "data/bolt/${{ matrix.city_dir }}/${{ matrix.venue_slug }}.txt" \
            --store-id "${{ matrix.store_id }}" \
            --out "${{ matrix.out }}" \
            --upsert-db main

      - name: Upload CSV artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.venue_slug }}-csv
          path: ${{ matrix.out }}
