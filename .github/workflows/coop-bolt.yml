name: Coop Bolt scrape + DB ingest

on:
  workflow_dispatch: {}
  schedule:
    # run every 6 hours (UTC); adjust if you want
    - cron: "0 */6 * * *"

jobs:
  scrape-bolt:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    # one job per Bolt venue you care about
    strategy:
      fail-fast: false
      matrix:
        include:
          # example entries ‚Äì adjust city/store/out paths to match
          - city: "2-tartu"
            store: "Coop Akadeemia"
            categories_dir: "data/bolt"
            outfile: "out/bolt_akadeemia.csv"

          - city: "2-tartu"
            store: "Coop Mustakivi"
            categories_dir: "data/bolt"
            outfile: "out/bolt_mustakivi.csv"

    env:
      TZ: Europe/Tallinn
      PYTHONUNBUFFERED: "1"

      # üîê must exist in repo secrets (Railway RW URL, NOT read-only)
      DATABASE_URL: ${{ secrets.RW_DATABASE_URL }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install crawler deps
        run: |
          python -m pip install --upgrade pip
          pip install playwright asyncpg
          playwright install --with-deps chromium

      - name: Run Bolt crawler + ingest
        run: |
          python bolt_crawler.py \
            --categories-dir "${{ matrix.categories_dir }}" \
            --city "${{ matrix.city }}" \
            --store "${{ matrix.store }}" \
            --out "${{ matrix.outfile }}" \
            --headless 1 \
            --req-delay 0.35
