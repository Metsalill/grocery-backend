name: Import approved matches (CSV to DB)

on:
  workflow_dispatch:
    inputs:
      run_set:
        description: "Which CSVs to import"
        type: choice
        options: [all, rimi, selver, prisma]
        default: all
      right_chain:
        description: "Target chain label for RIGHT side"
        required: true
        default: "Canonical"

jobs:
  import:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          - slug: rimi
            left_chain: Rimi
            csv_path: data/approved_rimi_matches.csv
          - slug: selver
            left_chain: Selver
            csv_path: data/approved_selver_matches.csv
          - slug: prisma
            left_chain: Prisma
            csv_path: data/approved_prisma_matches.csv

    steps:
      - name: Checkout
        if: ${{ github.event.inputs.run_set == 'all' || github.event.inputs.run_set == matrix.slug }}
        uses: actions/checkout@v4

      - name: Ensure CSV exists
        if: ${{ github.event.inputs.run_set == 'all' || github.event.inputs.run_set == matrix.slug }}
        shell: bash
        env:
          INPUT_CSV_PATH: ${{ matrix.csv_path }}
        run: |
          set -euo pipefail
          CSV_PATH="$GITHUB_WORKSPACE/$INPUT_CSV_PATH"
          echo "Checking CSV at: $CSV_PATH"
          test -f "$CSV_PATH" || { echo "CSV not found at: $CSV_PATH"; exit 1; }
          head -n 3 "$CSV_PATH" || true

      - name: Install tools
        if: ${{ github.event.inputs.run_set == 'all' || github.event.inputs.run_set == matrix.slug }}
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y postgresql-client python3

      - name: Normalize CSV → /tmp/normalized.csv
        if: ${{ github.event.inputs.run_set == 'all' || github.event.inputs.run_set == matrix.slug }}
        shell: bash
        env:
          INPUT_CSV_PATH: ${{ matrix.csv_path }}
          INPUT_LEFT_CHAIN: ${{ matrix.left_chain }}
          INPUT_RIGHT_CHAIN: ${{ github.event.inputs.right_chain }}
        run: |
          set -euo pipefail
          CSV_IN="$GITHUB_WORKSPACE/$INPUT_CSV_PATH"
          CSV_OUT="/tmp/normalized.csv"
          PY="/tmp/normalize_matches.py"
          : > "$PY"
          echo 'import csv, os' >> "$PY"
          echo 'csv_in = os.environ["CSV_IN"]' >> "$PY"
          echo 'csv_out = os.environ["CSV_OUT"]' >> "$PY"
          echo 'left_chain = os.environ["INPUT_LEFT_CHAIN"]' >> "$PY"
          echo 'right_chain = os.environ["INPUT_RIGHT_CHAIN"]' >> "$PY"
          echo 'def find_index(headers, candidates, default_idx):' >> "$PY"
          echo '    low = [h.strip().lower() for h in headers]' >> "$PY"
          echo '    for c in candidates:' >> "$PY"
          echo '        if c in low: return low.index(c)' >> "$PY"
          echo '    return default_idx' >> "$PY"
          echo 'with open(csv_in, "r", encoding="utf-8-sig", newline="") as f:' >> "$PY"
          echo '    r = csv.reader(f)' >> "$PY"
          echo '    headers = next(r)' >> "$PY"
          echo '    L = find_index(headers, ["left_key","left_id","left_product_id","left_hash","rimi_id","selver_id","prisma_id","source_id","source_key"], 0)' >> "$PY"
          echo '    R = find_index(headers, ["right_key","right_id","right_product_id","product_id","canonical_id","gtin","ean","canonical_ean","right_ean"], len(headers)-1)' >> "$PY"
          echo '    note_i = find_index(headers, ["note","notes","comment","comments"], -1)' >> "$PY"
          echo '    by_i   = find_index(headers, ["approved_by","approver","user","author"], -1)' >> "$PY"
          echo '    with open(csv_out, "w", encoding="utf-8", newline="") as g:' >> "$PY"
          echo '        w = csv.writer(g)' >> "$PY"
          echo '        w.writerow(["left_chain","left_key","right_chain","right_key","note","approved_by"])' >> "$PY"
          echo '        for row in r:' >> "$PY"
          echo '            if not row: continue' >> "$PY"
          echo '            need = max(L, R, note_i if note_i>=0 else 0, by_i if by_i>=0 else 0) + 1' >> "$PY"
          echo '            if len(row) < need: row = row + [""]*(need-len(row))' >> "$PY"
          echo '            lk = row[L].strip()' >> "$PY"
          echo '            rk = row[R].strip()' >> "$PY"
          echo '            if not lk or not rk: continue' >> "$PY"
          echo '            note = row[note_i].strip() if note_i >= 0 else ""' >> "$PY"
          echo '            by   = row[by_i].strip() if by_i >= 0 else ""' >> "$PY"
          echo '            w.writerow([left_chain, lk, right_chain, rk, note, by])' >> "$PY"
          env CSV_IN="$CSV_IN" CSV_OUT="$CSV_OUT" python3 "$PY"
          echo "Normalized preview:"
          head -n 5 "$CSV_OUT" || true

      - name: Import normalized CSV → approved_matches_active (upsert)
        if: ${{ github.event.inputs.run_set == 'all' || github.event.inputs.run_set == matrix.slug }}
        shell: bash
        env:
          DATABASE_URL_PUBLIC: ${{ secrets.DATABASE_URL_PUBLIC }}
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          PGHOST: ${{ secrets.PGHOST }}
          PGPORT: ${{ secrets.PGPORT }}
          PGUSER: ${{ secrets.PGUSER }}
          PGPASSWORD: ${{ secrets.PGPASSWORD }}
          PGDATABASE: ${{ secrets.PGDATABASE }}
        run: |
          set -euo pipefail

          # Resolve DB URL (prefer public, then private, then pieces)
          DB_URL="${DATABASE_URL_PUBLIC:-${DATABASE_URL:-}}"
          if [[ -z "$DB_URL" ]]; then
            DB_URL="postgresql://$PGUSER:$PGPASSWORD@$PGHOST:$PGPORT/$PGDATABASE"
          fi
          [[ "$DB_URL" == *"sslmode="* ]] || DB_URL="${DB_URL}?sslmode=require"

          echo "== Connectivity check =="
          psql "$DB_URL" -Atc "select current_database();" >/dev/null

          SQL="/tmp/import_matches.sql"
          : > "$SQL"
          {
            echo '\set ON_ERROR_STOP on'
            echo 'BEGIN;'
            echo 'CREATE TABLE IF NOT EXISTS approved_matches_active ('
            echo '  left_chain  text NOT NULL,'
            echo '  left_key    text NOT NULL,'
            echo '  right_chain text NOT NULL,'
            echo '  right_key   text NOT NULL,'
            echo '  note        text,'
            echo '  approved_by text,'
            echo '  approved_at timestamptz NOT NULL DEFAULT now(),'
            echo '  PRIMARY KEY (left_chain, left_key)'
            echo ');'
            echo 'DROP TABLE IF EXISTS approved_matches_import;'
            echo 'CREATE TEMP TABLE approved_matches_import ('
            echo '  left_chain  text,'
            echo '  left_key    text,'
            echo '  right_chain text,'
            echo '  right_key   text,'
            echo '  note        text,'
            echo '  approved_by text'
            echo ');'
            echo "\\copy approved_matches_import (left_chain,left_key,right_chain,right_key,note,approved_by) FROM '/tmp/normalized.csv' CSV HEADER;"
            echo 'INSERT INTO approved_matches_active (left_chain,left_key,right_chain,right_key,note,approved_by)'
            echo 'SELECT left_chain,left_key,right_chain,right_key,note,approved_by'
            echo 'FROM approved_matches_import'
            echo 'WHERE left_key IS NOT NULL AND right_key IS NOT NULL'
            echo 'ON CONFLICT (left_chain,left_key) DO UPDATE'
            echo '  SET right_chain = EXCLUDED.right_chain,'
            echo '      right_key   = EXCLUDED.right_key,'
            echo '      note        = COALESCE(EXCLUDED.note, approved_matches_active.note),'
            echo '      approved_by = COALESCE(EXCLUDED.approved_by, approved_matches_active.approved_by),'
            echo '      approved_at = now();'
            echo 'COMMIT;'
            echo "SELECT left_chain, COUNT(*) AS rows FROM approved_matches_active GROUP BY 1 ORDER BY 1;"
          } >> "$SQL"

          echo "=== Executing SQL ==="
          sed -n '1,180p' "$SQL" || true
          psql "$DB_URL" -f "$SQL"

      - name: Show sample rows
        if: ${{ github.event.inputs.run_set == 'all' || github.event.inputs.run_set == matrix.slug }}
        shell: bash
        env:
          DATABASE_URL_PUBLIC: ${{ secrets.DATABASE_URL_PUBLIC }}
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          PGHOST: ${{ secrets.PGHOST }}
          PGPORT: ${{ secrets.PGPORT }}
          PGUSER: ${{ secrets.PGUSER }}
          PGPASSWORD: ${{ secrets.PGPASSWORD }}
          PGDATABASE: ${{ secrets.PGDATABASE }}
        run: |
          set -euo pipefail
          DB_URL="${DATABASE_URL_PUBLIC:-${DATABASE_URL:-}}"
          if [[ -z "$DB_URL" ]]; then
            DB_URL="postgresql://$PGUSER:$PGPASSWORD@$PGHOST:$PGPORT/$PGDATABASE"
          fi
          [[ "$DB_URL" == *"sslmode="* ]] || DB_URL="${DB_URL}?sslmode=require"
          psql "$DB_URL" -c "TABLE approved_matches_active LIMIT 15;"
