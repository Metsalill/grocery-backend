name: Import approved matches to Railway

on:
  workflow_dispatch:
    inputs:
      csv_dir:
        description: Folder with approved_*_matches.csv files
        required: true
        default: data

jobs:
  import:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install psql client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Prepare DATABASE_URL (public) with sslmode=require
        id: prep
        env:
          DBURL_PUBLIC: ${{ secrets.DATABASE_URL_PUBLIC }}
          DBURL: ${{ secrets.DATABASE_URL }}
        run: |
          set -euo pipefail
          URL="${DBURL_PUBLIC:-$DBURL}"
          if [[ -z "$URL" ]]; then
            echo "No DATABASE_URL_PUBLIC or DATABASE_URL secret set." >&2
            exit 1
          fi
          if [[ "$URL" == *"?"* ]]; then
            [[ "$URL" == *"sslmode="* ]] || URL="${URL}&sslmode=require"
          else
            URL="${URL}?sslmode=require"
          fi
          echo "url=$URL" >> "$GITHUB_OUTPUT"

      - name: Create table + indexes (if not exists)
        env:
          DATABASE_URL: ${{ steps.prep.outputs.url }}
        run: |
          set -euo pipefail
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "
            CREATE TABLE IF NOT EXISTS approved_matches (
              barbora_uid   text NOT NULL,
              barbora_name  text,
              barbora_brand text,
              barbora_size  text,
              match_uid     text NOT NULL,
              match_name    text,
              match_brand   text,
              match_size    text,
              match_ean     text,
              store         text NOT NULL,
              similarity    numeric(5,4),
              size_diff_pct numeric(6,2),
              tier          text,
              is_best_match boolean,
              reviewed_at   timestamptz DEFAULT now(),
              PRIMARY KEY (barbora_uid, store, match_uid)
            );
            CREATE INDEX IF NOT EXISTS idx_approved_matches_barbora_uid ON approved_matches (barbora_uid);
            CREATE INDEX IF NOT EXISTS idx_approved_matches_store_match_uid ON approved_matches (store, match_uid);
          "
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "
            CREATE OR REPLACE VIEW approved_best_match_per_store AS
            SELECT DISTINCT ON (barbora_uid, store)
                   barbora_uid, store, match_uid, match_ean,
                   similarity, tier, is_best_match,
                   barbora_name, barbora_brand, barbora_size,
                   match_name, match_brand, match_size
            FROM approved_matches
            ORDER BY barbora_uid, store, is_best_match DESC, similarity DESC, tier ASC, match_uid;
          "

      - name: Import approved matches (Selver, Rimi, Prisma)
        env:
          DATABASE_URL: ${{ steps.prep.outputs.url }}
          CSV_DIR: ${{ github.event.inputs.csv_dir }}
          GITHUB_WORKSPACE: ${{ github.workspace }}
        run: |
          set -euo pipefail
          ls -lah "$GITHUB_WORKSPACE/$CSV_DIR" || true

          import_one () {
            local chain="$1"
            local rel="$2"
            local abs="$GITHUB_WORKSPACE/$rel"

            echo "Importing $chain from $rel"
            if [[ ! -f "$abs" ]]; then
              echo "::error file=$rel::File not found"; exit 1
            fi

            psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "
              DROP TABLE IF EXISTS _stage_approved;
              CREATE TEMP TABLE _stage_approved (
                barbora_uid   text,
                barbora_name  text,
                barbora_brand text,
                barbora_size  text,
                match_uid     text,
                match_name    text,
                match_brand   text,
                match_size    text,
                match_ean     text,
                store         text,
                similarity    numeric(5,4),
                size_diff_pct numeric(6,2),
                tier          text,
                is_best_match boolean
              );
            "
            psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -v file="$abs" -c "\copy _stage_approved FROM :'file' WITH CSV HEADER ENCODING 'UTF8';"
            psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "
              INSERT INTO approved_matches
              (barbora_uid, barbora_name, barbora_brand, barbora_size,
               match_uid, match_name, match_brand, match_size, match_ean,
               store, similarity, size_diff_pct, tier, is_best_match)
              SELECT
                NULLIF(BTRIM(barbora_uid), ''),
                barbora_name, barbora_brand, barbora_size,
                NULLIF(BTRIM(match_uid), ''),
                match_name, match_brand, match_size, match_ean,
                LOWER(COALESCE(NULLIF(BTRIM(store), ''), '${chain}')),
                similarity, size_diff_pct, tier, is_best_match
              FROM _stage_approved
              WHERE NULLIF(BTRIM(barbora_uid),'') IS NOT NULL
                AND NULLIF(BTRIM(match_uid),'') IS NOT NULL
              ON CONFLICT (barbora_uid, store, match_uid) DO UPDATE SET
                barbora_name   = EXCLUDED.barbora_name,
                barbora_brand  = EXCLUDED.barbora_brand,
                barbora_size   = EXCLUDED.barbora_size,
                match_name     = EXCLUDED.match_name,
                match_brand    = EXCLUDED.match_brand,
                match_size     = EXCLUDED.match_size,
                match_ean      = EXCLUDED.match_ean,
                similarity     = EXCLUDED.similarity,
                size_diff_pct  = EXCLUDED.size_diff_pct,
                tier           = EXCLUDED.tier,
                is_best_match  = EXCLUDED.is_best_match,
                reviewed_at    = now();
            "
          }

          import_one "selver"  "$CSV_DIR/approved_selver_matches.csv"
          import_one "rimi"    "$CSV_DIR/approved_rimi_matches.csv"
          import_one "prisma"  "$CSV_DIR/approved_prisma_matches.csv"

      - name: Sanity counts
        env:
          DATABASE_URL: ${{ steps.prep.outputs.url }}
        run: |
          set -euo pipefail
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "\pset footer off"
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "SELECT 'approved_matches' AS table, COUNT(*) AS rows FROM approved_matches;"
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "SELECT store, COUNT(*) FROM approved_matches GROUP BY store ORDER BY 1;"
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "SELECT COUNT(*) FROM approved_best_match_per_store;"
