name: Coop V채ndra EAN backfill (from Haapsalu matches)

on:
  workflow_dispatch:
    inputs:
      wipe_before:
        description: Wipe existing V채ndra EANs before backfill? (yes/no)
        required: true
        default: "no"
      strong_csv:
        description: Path to coop_match_strong.csv (in repo)
        required: true
        default: data/coop_match_strong.csv
      medium_csv:
        description: Path to coop_match_medium.csv (in repo)
        required: true
        default: data/coop_match_medium.csv
      weak_csv:
        description: Path to coop_match_weak.csv (in repo)
        required: true
        default: data/coop_match_weak.csv

jobs:
  backfill:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install tools
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client python3 python3-pip
          python3 -V
          psql --version

      - name: Verify CSVs exist
        run: |
          for f in "${{ inputs.strong_csv }}" "${{ inputs.medium_csv }}" "${{ inputs.weak_csv }}"; do
            [ -f "$f" ] || { echo "::error::Missing file: $f"; exit 1; }
            echo "Found $f"
            head -n 1 "$f"
          done

      - name: Build 2-column map CSV (vandra_ext_id, ean)
        id: buildmap
        run: |
          python3 - <<'PY'
          import csv, sys, os
          from pathlib import Path

          files = [
            Path("${{ inputs.strong_csv }}"),
            Path("${{ inputs.medium_csv }}"),
            Path("${{ inputs.weak_csv }}"),
          ]

          out_path = Path("/tmp/vandra_map.csv")
          seen = set()
          n_in, n_out = 0, 0

          def clean_ean(s):
            if s is None: return ""
            s = str(s).strip()
            if s.endswith(".0"): s = s[:-2]
            return s

          with out_path.open("w", newline="", encoding="utf-8") as f_out:
            w = csv.writer(f_out)
            w.writerow(["vandra_ext_id", "ean"])
            for fp in files:
              with fp.open("r", encoding="utf-8") as f_in:
                r = csv.DictReader(f_in)
                # tolerate header variants
                ve_keys = [k for k in r.fieldnames if k and k.lower().strip()=="vandra_ext_id"]
                ean_keys = [k for k in r.fieldnames if k and k.lower().strip()=="ean_to_copy_to_vandra"]
                if not ve_keys or not ean_keys:
                  print(f"::error::Required columns not found in {fp.name}. Found headers: {r.fieldnames}", file=sys.stderr)
                  sys.exit(1)
                ve, ek = ve_keys[0], ean_keys[0]
                for row in r:
                  n_in += 1
                  ext = (row.get(ve) or "").strip()
                  ean = clean_ean(row.get(ek))
                  if not ext or not ean: 
                    continue
                  key = (ext, ean)
                  if key in seen:
                    continue
                  seen.add(key)
                  w.writerow([ext, ean])
                  n_out += 1

          print(f"Built map at {out_path}  rows_in={n_in}  unique_pairs={n_out}")
          print(f"::set-output name=map_path::{out_path}")
          PY

      - name: Before counts
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL_PUBLIC }}
        run: |
          cat > before.sql <<'SQL'
          WITH latest AS (
            SELECT DISTINCT ON (store_host, ext_id) *
            FROM staging_coop_products
            WHERE store_host IN ('coophaapsalu.ee','vandra.ecoop.ee')
            ORDER BY store_host, ext_id, scraped_at DESC
          )
          SELECT
            store_host,
            COUNT(DISTINCT ext_id) AS distinct_products,
            COUNT(DISTINCT NULLIF(COALESCE(ean_norm, ean_raw), '')) AS unique_eans
          FROM latest
          GROUP BY store_host
          ORDER BY store_host;
          SQL
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -f before.sql

      - name: Wipe existing V채ndra EANs (optional)
        if: ${{ inputs.wipe_before == 'yes' }}
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL_PUBLIC }}
        run: |
          cat > wipe.sql <<'SQL'
          BEGIN;
          UPDATE staging_coop_products
          SET ean_norm = NULL, ean_raw = NULL
          WHERE store_host = 'vandra.ecoop.ee'
            AND (COALESCE(ean_norm,'') <> '' OR COALESCE(ean_raw,'') <> '');
          COMMIT;
          SQL
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -f wipe.sql

      - name: Backfill from matches (only V채ndra)
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL_PUBLIC }}
        run: |
          echo "Using map: ${{ steps.buildmap.outputs.map_path }}"
          test -f "${{ steps.buildmap.outputs.map_path }}" || { echo "::error::map file missing"; exit 1; }

          cat > backfill.sql <<'SQL'
          BEGIN;

          DROP TABLE IF EXISTS tmp_vandra_ean_map;
          CREATE TEMP TABLE tmp_vandra_ean_map (
            vandra_ext_id text,
            ean text
          );

          \copy tmp_vandra_ean_map (vandra_ext_id, ean) FROM '${{ steps.buildmap.outputs.map_path }}' WITH (FORMAT csv, HEADER true)

          CREATE UNIQUE INDEX ON tmp_vandra_ean_map(vandra_ext_id);

          WITH upd AS (
            UPDATE staging_coop_products s
            SET
              ean_norm = COALESCE(NULLIF(s.ean_norm,''), m.ean),
              ean_raw  = COALESCE(NULLIF(s.ean_raw,''),  m.ean)
            FROM tmp_vandra_ean_map m
            WHERE s.store_host = 'vandra.ecoop.ee'
              AND s.ext_id = m.vandra_ext_id
              AND (NULLIF(s.ean_norm,'') IS NULL OR NULLIF(s.ean_raw,'') IS NULL)
            RETURNING s.ext_id
          )
          SELECT COUNT(*) AS vandra_rows_updated FROM upd;

          COMMIT;
          SQL

          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -f backfill.sql

      - name: After counts
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL_PUBLIC }}
        run: |
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -f before.sql
