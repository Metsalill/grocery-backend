name: Selver - Seed stores (online + physical)

on:
  workflow_dispatch:
    inputs:
      geocode:
        description: "Geocode with Nominatim (0/1). If 1, adds lat/lon (slower)."
        required: false
        default: "0"
      chain:
        description: "Retail chain label"
        required: false
        default: "Selver"
      online_name:
        description: "Name of online store"
        required: false
        default: "e-Selver"
      dry_run:
        description: "Dry run (0/1) - parse only, no DB writes"
        required: false
        default: "0"

concurrency:
  group: seed-selver-stores
  cancel-in-progress: true

jobs:
  seed:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    env:
      DATABASE_URL: ${{ secrets.RW_DATABASE_URL }}
      GEOCODE: ${{ github.event.inputs.geocode }}
      DRY_RUN: ${{ github.event.inputs.dry_run }}
      SELVER_CHAIN: ${{ github.event.inputs.chain }}
      ONLINE_NAME: ${{ github.event.inputs.online_name }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps (Playwright + DB + HTTP)
        run: |
          python -m pip install --upgrade pip
          pip install playwright psycopg2-binary aiohttp
          python -m playwright install --with-deps chromium

      - name: Create Playwright seeder script (inline)
        shell: bash
        run: |
          cat > selver_seed_stores_pw.py << 'PY'
          import os, re, time, sys, asyncio, aiohttp
          import psycopg2
          from playwright.sync_api import sync_playwright

          DB_URL = os.environ.get("DATABASE_URL")
          if not DB_URL:
            print("::error::DATABASE_URL secret not set"); sys.exit(1)

          GEOCODE = os.environ.get("GEOCODE","0") == "1"
          DRY_RUN = os.environ.get("DRY_RUN","0") == "1"
          CHAIN   = os.environ.get("SELVER_CHAIN","Selver")
          ONLINE  = os.environ.get("ONLINE_NAME","e-Selver")

          # Regexes
          SCHEDULE_SPLIT = re.compile(r'\s+(?:E[-–]?P|E[-–]?[A-Z](?:\s*\d)?)\b')
          CITY_PREFIX_RE = re.compile(
              r'^(Tallinn|Tartu|Pärnu|Narva|Jõhvi|Kohtla[-\s]?Järve|Rakvere|Paide|Keila|Võru|Valga|Viljandi|Rapla|Põlva|Jõgeva|Kuressaare|Kärdla|Maardu|Saue|Laagri|Kurna|Peetri|Viimsi|Merimetsa|Astri)\s+(.*)$',
              re.I
          )
          # Match “… Selver” or “… Selver ABC” with a reasonable prefix length
          SELVER_RE = re.compile(r'([A-ZÄÖÜÕ][A-Za-zÄÖÜÕäöüõ0-9\'’\- ]{1,50}\sSelver(?:\sABC)?)')
          # Match "Delice …" or "Delice Toidupood …"
          DELICE_RE = re.compile(r'(Delice(?:\s+Toidupood)?\s[A-ZÄÖÜÕ][A-Za-zÄÖÜÕäöüõ0-9\'’\- ]{1,50})')

          def clean_one(name: str) -> str:
              # trim hours and whitespace
              n = SCHEDULE_SPLIT.split(name)[0].strip()
              # strip leading city if present and the rest still contains "Selver"
              m = CITY_PREFIX_RE.match(n)
              if m:
                  rest = m.group(2).strip()
                  if re.search(r'\bSelver\b', rest, re.I):
                      n = rest
              n = re.sub(r'\s{2,}', ' ', n)
              # drop e-Selver variants
              if re.search(r'\be-?selver\b', n, re.I):
                  return ''
              return n

          def render_and_extract():
              with sync_playwright() as pw:
                  b = pw.chromium.launch(headless=True)
                  p = b.new_page()
                  p.goto("https://www.selver.ee/kauplused", wait_until="domcontentloaded", timeout=60000)

                  # Accept cookies (best-effort)
                  for txt in ["Nõustun", "Nõustu", "Accept", "Allow all", "OK"]:
                      try:
                          p.get_by_role("button", name=re.compile(txt, re.I)).click(timeout=1200)
                          break
                      except Exception:
                          pass

                  p.wait_for_timeout(2000)

                  # Use full page text; regex find all store-like fragments
                  try:
                      body_text = p.evaluate("document.body.innerText") or ""
                  except Exception:
                      body_text = p.inner_text("body") if p.locator("body").count() else ""

                  names = set()
                  for m in SELVER_RE.finditer(body_text):
                      n = clean_one(m.group(1))
                      if n:
                          names.add(n)

                  for m in DELICE_RE.finditer(body_text):
                      n = clean_one(m.group(1))
                      if n:
                          names.add(n)

                  # Final pass: keep only strings that actually end with "Selver" or "Selver ABC"
                  # or start with "Delice"
                  final = set()
                  for n in names:
                      if re.search(r'(?:\bSelver(?:\sABC)?$)', n) or re.match(r'^Delice\b', n):
                          final.add(n)

                  b.close()
                  return sorted(final)

          async def geocode_one(session, name):
              url = "https://nominatim.openstreetmap.org/search"
              params = {"q": f"{name}, Estonia", "format": "json", "limit": 1}
              headers = {"User-Agent": "grocery-backend/seed-selver-stores (+gha)"}
              try:
                  async with session.get(url, params=params, headers=headers, timeout=30) as r:
                      r.raise_for_status()
                      data = await r.json()
                      if not data: return None, None
                      return float(data[0]["lat"]), float(data[0]["lon"])
              except Exception:
                  return None, None

          async def geocode_all(names):
              if not GEOCODE:
                  return {n: (None, None) for n in names}
              out = {}
              async with aiohttp.ClientSession() as session:
                  for n in names:
                      lat, lon = await geocode_one(session, n)
                      out[n] = (lat, lon)
                      time.sleep(1)  # Nominatim fair use
              return out

          def upsert(names, coords):
              if DRY_RUN:
                  print(f"Dry run: {len(names)} stores parsed")
                  for n in names: print(" -", n)
                  return

              conn = psycopg2.connect(DB_URL)
              conn.autocommit = True
              cur = conn.cursor()

              # Ensure columns exist (idempotent)
              cur.execute("""
              DO $$
              BEGIN
                IF NOT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name='stores' AND column_name='chain') THEN
                  ALTER TABLE stores ADD COLUMN chain TEXT;
                END IF;
                IF NOT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name='stores' AND column_name='is_online') THEN
                  ALTER TABLE stores ADD COLUMN is_online BOOLEAN NOT NULL DEFAULT FALSE;
                END IF;
                IF NOT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name='stores' AND column_name='lat') THEN
                  ALTER TABLE stores ADD COLUMN lat DOUBLE PRECISION;
                END IF;
                IF NOT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name='stores' AND column_name='lon') THEN
                  ALTER TABLE stores ADD COLUMN lon DOUBLE PRECISION;
                END IF;
              END $$;""")

              # Upsert online store
              cur.execute("""
                INSERT INTO stores (name, chain, is_online)
                VALUES (%s, %s, TRUE)
                ON CONFLICT DO NOTHING;
              """, (ONLINE, CHAIN))

              # Upsert physical stores
              sql = """
                INSERT INTO stores (name, chain, is_online, lat, lon)
                VALUES (%s, %s, FALSE, %s, %s)
                ON CONFLICT DO NOTHING;
              """
              for n in names:
                lat, lon = coords.get(n, (None, None))
                cur.execute(sql, (n, CHAIN, lat, lon))

              cur.close(); conn.close()
              print(f"Upsert complete: {len(names)} physical stores")

          if __name__ == "__main__":
              names = render_and_extract()
              print(f"Found {len(names)} Selver/Delice physical names.")
              coords = asyncio.run(geocode_all(names))
              upsert(names, coords)
          PY

      - name: Run seeder
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          echo "GEOCODE=${GEOCODE} DRY_RUN=${DRY_RUN} CHAIN=${SELVER_CHAIN} ONLINE_NAME=${ONLINE_NAME}"
          python selver_seed_stores_pw.py
