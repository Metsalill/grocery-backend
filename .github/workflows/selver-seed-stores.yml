name: Selver - Seed/Backfill stores (online + physical)

on:
  workflow_dispatch:
    inputs:
      backfill_only:
        description: "Backfill only rows with missing/zero lat/lon from DB (1) or do full scrape+seed (0)"
        required: false
        default: "1"
      geocode:
        description: "Geocode with Nominatim (0/1). If 1, adds lat/lon (slower)."
        required: false
        default: "1"
      chain:
        description: "Retail chain label"
        required: false
        default: "Selver"
      online_name:
        description: "Name of online store"
        required: false
        default: "e-Selver"
      dry_run:
        description: "Dry run (0/1) - parse only, no DB writes"
        required: false
        default: "0"

concurrency:
  group: seed-selver-stores
  cancel-in-progress: true

jobs:
  seed:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    env:
      DATABASE_URL: ${{ secrets.RW_DATABASE_URL }}
      BACKFILL_ONLY: ${{ github.event.inputs.backfill_only }}
      GEOCODE: ${{ github.event.inputs.geocode }}
      DRY_RUN: ${{ github.event.inputs.dry_run }}
      SELVER_CHAIN: ${{ github.event.inputs.chain }}
      ONLINE_NAME: ${{ github.event.inputs.online_name }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps (Playwright + DB + HTTP + HTML parse)
        run: |
          python -m pip install --upgrade pip
          pip install playwright psycopg2-binary aiohttp beautifulsoup4
          python -m playwright install --with-deps chromium

      - name: Create Playwright seeder/backfiller script (inline)
        shell: bash
        run: |
          cat > selver_seed_stores_pw.py << 'PY'
          import os, re, time, sys, asyncio, aiohttp
          import psycopg2
          import psycopg2.extras
          from urllib.parse import urlparse, parse_qs, unquote
          from bs4 import BeautifulSoup
          from playwright.sync_api import sync_playwright

          DB_URL = os.environ.get("DATABASE_URL")
          if not DB_URL:
            print("::error::DATABASE_URL secret not set"); sys.exit(1)

          BACKFILL_ONLY = os.environ.get("BACKFILL_ONLY","1") == "1"
          GEOCODE = os.environ.get("GEOCODE","1") == "1"
          DRY_RUN = os.environ.get("DRY_RUN","0") == "1"
          CHAIN   = os.environ.get("SELVER_CHAIN","Selver")
          ONLINE  = os.environ.get("ONLINE_NAME","e-Selver")

          # schedules like "E-P 08:00–23:00"
          SCHEDULE_SPLIT = re.compile(r'\s+(?:E[-–]?P|E[-–]?[A-Z](?:\s*\d)?)\b')
          CITY_PREFIX_RE = re.compile(r'^(Tallinn|Tartu)\s+(.*)$', re.I)

          CAP_NAME = re.compile(r'(Delice(?:\s+Toidupood)?|[A-ZÄÖÜÕ][A-Za-zÄÖÜÕäöüõ0-9\'’\- ]{1,60}\sSelver(?:\sABC)?)')
          BAD_NAME = re.compile(r'^(?:e-?Selver|Selver)$', re.I)

          ADDR_TOKEN = re.compile(r'\b(mnt|tee|tn|pst|puiestee|maantee|tänav|keskus|turg|väljak|tee\.)\b', re.I)

          def clean_name(s: str) -> str:
              n = SCHEDULE_SPLIT.split(s or "")[0].strip()
              m = CITY_PREFIX_RE.match(n)
              if m:
                  rest = m.group(2).strip()
                  if 'selver' in rest.lower() and rest.lower() != 'selver':
                      n = rest
              n = re.sub(r'\s{2,}', ' ', n)
              m = CAP_NAME.search(n)
              if m: n = m.group(1)
              if BAD_NAME.match(n): return ''
              if re.search(r'\be-?selver\b', n, re.I): return ''
              return n.strip()

          def extract_from_html(html: str):
              soup = BeautifulSoup(html, 'html.parser')
              results =
