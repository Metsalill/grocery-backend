name: Selver - Seed stores (online + physical)

on:
  workflow_dispatch:
    inputs:
      geocode:
        description: "Geocode with Nominatim (0/1). If 1, adds lat/lon (slower)."
        required: false
        default: "0"
      chain:
        description: "Retail chain label"
        required: false
        default: "Selver"
      online_name:
        description: "Name of online store"
        required: false
        default: "e-Selver"
      dry_run:
        description: "Dry run (0/1) - parse only, no DB writes"
        required: false
        default: "0"

concurrency:
  group: seed-selver-stores
  cancel-in-progress: true

jobs:
  seed:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    env:
      DATABASE_URL: ${{ secrets.RW_DATABASE_URL }}
      GEOCODE: ${{ github.event.inputs.geocode }}
      DRY_RUN: ${{ github.event.inputs.dry_run }}
      SELVER_CHAIN: ${{ github.event.inputs.chain }}
      ONLINE_NAME: ${{ github.event.inputs.online_name }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps (Playwright + DB + HTTP)
        run: |
          python -m pip install --upgrade pip
          pip install playwright psycopg2-binary aiohttp
          python -m playwright install --with-deps chromium

      - name: Create Playwright seeder script (inline)
        shell: bash
        run: |
          cat > selver_seed_stores_pw.py << 'PY'
          import os, re, time, sys, asyncio, aiohttp
          import psycopg2
          from playwright.sync_api import sync_playwright

          DB_URL = os.environ.get("DATABASE_URL")
          if not DB_URL:
            print("::error::DATABASE_URL secret not set"); sys.exit(1)

          GEOCODE = os.environ.get("GEOCODE","0") == "1"
          DRY_RUN = os.environ.get("DRY_RUN","0") == "1"
          CHAIN   = os.environ.get("SELVER_CHAIN","Selver")
          ONLINE  = os.environ.get("ONLINE_NAME","e-Selver")

          # schedules like "E-P 08:00–23:00"
          SCHEDULE_SPLIT = re.compile(r'\s+(?:E[-–]?P|E[-–]?[A-Z](?:\s*\d)?)\b')
          # strip only noisy prefixes that create duplicates
          CITY_PREFIX_RE = re.compile(r'^(Tallinn|Tartu)\s+(.*)$', re.I)

          # capture "... Selver" or "... Selver ABC"
          CAP_SELVER = re.compile(r'([A-ZÄÖÜÕ][A-Za-zÄÖÜÕäöüõ0-9\'’\- ]{1,60}\sSelver(?:\sABC)?)')
          # capture "Delice ..." or "Delice Toidupood ..."
          CAP_DELICE = re.compile(r'(Delice(?:\s+Toidupood)?\s[A-ZÄÖÜÕ][A-Za-zÄÖÜÕäöüõ0-9\'’\- ]{1,60})')

          def clean_one(name: str) -> str:
              n = SCHEDULE_SPLIT.split(name)[0].strip()
              m = CITY_PREFIX_RE.match(n)
              if m:
                  rest = m.group(2).strip()
                  if re.search(r'\bSelver\b', rest, re.I) and rest.lower() != 'selver':
                      n = rest
              n = re.sub(r'\s{2,}', ' ', n)
              if n.lower() == 'selver' or re.fullmatch(r'osta selver', n, re.I):
                  return ''
              if re.search(r'\be-?selver\b', n, re.I):
                  return ''
              return n

          def extract_all(text: str):
              names = set()
              missed = set()
              lines = [re.sub(r'\s+', ' ', raw).strip() for raw in re.split(r'[\r\n]+', text)]
              lines = [ln for ln in lines if ln and 'selver' in ln.lower()]
              for line in lines:
                  got = False
                  for m in CAP_SELVER.finditer(line):
                      n = clean_one(m.group(1))
                      if n: names.add(n); got = True
                  for m in CAP_DELICE.finditer(line):
                      n = clean_one(m.group(1))
                      if n: names.add(n); got = True
                  if not got:
                      m = re.search(r'([A-ZÄÖÜÕ0-9][A-Za-zÄÖÜÕäöüõ0-9\'’\- ]{1,80}\sSelver(?:\sABC)?)(?:\W|$)', line)
                      if m:
                          n = clean_one(m.group(1))
                          if n: names.add(n); got = True
                  if not got:
                      missed.add(line)
              final = []
              for n in names:
                  if re.search(r'(?:\bSelver(?:\sABC)?$)', n) or re.match(r'^Delice\b', n):
                      final.append(n)
              final = sorted(set(final))
              if len(final) < 73:
                  print(f"::warning::Captured {len(final)}; showing up to 25 unmatched Selver-lines:")
                  for s in list(missed)[:25]:
                      print("UNMATCHED:", s)
              return final

          def render_and_extract():
              with sync_playwright() as pw:
                  b = pw.chromium.launch(headless=True)
                  p = b.new_page()
                  p.goto("https://www.selver.ee/kauplused", wait_until="domcontentloaded", timeout=60000)
                  for txt in ["Nõustun", "Nõustu", "Accept", "Allow all", "OK"]:
                      try:
                          p.get_by_role("button", name=re.compile(txt, re.I)).click(timeout=1200)
                          break
                      except Exception:
                          pass
                  p.wait_for_timeout(2000)
                  try:
                      body_text = p.evaluate("document.body.innerText") or ""
                  except Exception:
                      body_text = p.inner_text("body") if p.locator("body").count() else ""
                  names = extract_all(body_text)
                  if not names:
                      print("::warning::No names extracted; sample dump follows:")
                      print(body_text[:2000])
                  b.close()
                  return names

          async def geocode_one(session, name):
              url = "https://nominatim.openstreetmap.org/search"
              params = {"q": f"{name}, Estonia", "format": "json", "limit": 1}
              headers = {"User-Agent": "grocery-backend/seed-selver-stores (+gha)"}
              try:
                  async with session.get(url, params=params, headers=headers, timeout=30) as r:
                      r.raise_for_status()
                      data = await r.json()
                      if not data: return None, None
                      return float(data[0]["lat"]), float(data[0]["lon"])
              except Exception:
                  return None, None

          async def geocode_all(names):
              if not GEOCODE:
                  return {n: (None, None) for n in names}
              out = {}
              async with aiohttp.ClientSession() as session:
                  for n in names:
                      lat, lon = await geocode_one(session, n)
                      out[n] = (lat, lon)
                      time.sleep(1)
              return out

          def upsert(names, coords):
              if DRY_RUN:
                  print(f"Dry run: {len(names)} stores parsed")
                  for n in names: print(" -", n)
                  return
              conn = psycopg2.connect(DB_URL); conn.autocommit = True
              cur = conn.cursor()
              cur.execute("""
              DO $$ BEGIN
                IF NOT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name='stores' AND column_name='chain') THEN
                  ALTER TABLE stores ADD COLUMN chain TEXT;
                END IF;
                IF NOT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name='stores' AND column_name='is_online') THEN
                  ALTER TABLE stores ADD COLUMN is_online BOOLEAN NOT NULL DEFAULT FALSE;
                END IF;
                IF NOT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name='stores' AND column_name='lat') THEN
                  ALTER TABLE stores ADD COLUMN lat DOUBLE PRECISION;
                END IF;
                IF NOT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name='stores' AND column_name='lon') THEN
                  ALTER TABLE stores ADD COLUMN lon DOUBLE PRECISION;
                END IF;
              END $$;""")

              # Online store (idempotent; respects uniq_chain_online on lower(chain) WHERE is_online)
              cur.execute("""
                WITH existing AS (
                  SELECT 1
                  FROM stores
                  WHERE lower(chain)=lower(%s) AND COALESCE(is_online,false)=true
                  LIMIT 1
                )
                INSERT INTO stores (name, chain, is_online)
                SELECT %s, %s, TRUE
                WHERE NOT EXISTS (SELECT 1 FROM existing);
              """, (CHAIN, ONLINE, CHAIN))

              # Physical stores
              sql = """
                INSERT INTO stores (name, chain, is_online, lat, lon)
                SELECT %s, %s, FALSE, %s, %s
                WHERE NOT EXISTS (
                  SELECT 1 FROM stores WHERE chain=%s AND name=%s AND COALESCE(is_online,false)=false
                );
              """
              for n in names:
                lat, lon = coords.get(n, (None, None))
                cur.execute(sql, (n, CHAIN, lat, lon, CHAIN, n))
              cur.close(); conn.close()
              print(f"Upsert complete: {len(names)} physical stores")

          if __name__ == "__main__":
              names = render_and_extract()
              print(f"Found {len(names)} Selver/Delice physical names.")
              coords = asyncio.run(geocode_all(names))
              upsert(names, coords)
          PY

      - name: Run seeder
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          echo "GEOCODE=${GEOCODE} DRY_RUN=${DRY_RUN} CHAIN=${SELVER_CHAIN} ONLINE_NAME=${ONLINE_NAME}"
          python selver_seed_stores_pw.py
