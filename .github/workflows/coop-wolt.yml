name: Coop Wolt Crawl + Ingest

on:
  workflow_dispatch: {}
  schedule:
    # every 6 hours
    - cron: "0 */6 * * *"

jobs:
  crawl-wolt:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    strategy:
      fail-fast: false
      matrix:
        include:
          # id 551 — Pärnu
          - store_id: "551"
            city: "parnu"
            store_host: "coop-prnu"
          # id 552 — Laagri
          - store_id: "552"
            city: "tallinn"
            store_host: "coop-laagri"
          # id 553 — Jüri (Konsum)
          - store_id: "553"
            city: "tallinn"
            store_host: "konsum-juri"
          # id 554 — Miiduranna
          - store_id: "554"
            city: "tallinn"
            store_host: "coop-miiduranna"
          # id 555 — Akadeemia (Tartu)
          - store_id: "555"
            city: "tartu"
            store_host: "coop-akadeemia"
          # id 556 — Lasnamäe (note the slug!)
          - store_id: "556"
            city: "tallinn"
            store_host: "coop-lasname"
          # id 557 — Mustakivi
          - store_id: "557"
            city: "tallinn"
            store_host: "coop-mustakivi"

    env:
      DATABASE_URL: ${{ secrets.RW_DATABASE_URL }}
      PYTHONUNBUFFERED: "1"
      # The crawler reads STORE_ID from env
      STORE_ID: ${{ matrix.store_id }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests selectolax tenacity

      - name: Crawl & ingest this Wolt store
        run: |
          python3 scripts/wolt_crawler.py \
            --store-host "${{ matrix.store_host }}" \
            --city "${{ matrix.city }}" \
            --categories-file "data/wolt_categories_slugs.txt" \
            --ingest-mode main
