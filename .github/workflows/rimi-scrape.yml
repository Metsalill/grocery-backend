name: "Rimi → Full scrape (categories → CSV/DB)"

on:
  workflow_dispatch:
    inputs:
      categories_multiline:
        description: "Paste Rimi category URLs (one per line). Example: https://www.rimi.ee/epood/ee/tooted/leivad-saiad-kondiitritooted"
        required: false
        default: ""
      page_limit:
        description: "Max category pages per category (0 = all)"
        required: false
        default: "0"
      max_products:
        description: "Hard cap on total PDPs (0 = unlimited)"
        required: false
        default: "0"
      headless:
        description: "Headless browser (1/0)"
        required: false
        default: "1"
      req_delay:
        description: "Delay between page ops (sec, can be 0.0)"
        required: false
        default: "0.4"
  schedule:
    - cron: "17 2 * * *"   # nightly

concurrency:
  group: rimi-scrape
  cancel-in-progress: true

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    env:
      PYTHONUNBUFFERED: "1"
      # Optional: set in repo secrets if you want DB upserts
      # DATABASE_URL: ${{ secrets.DATABASE_URL_PUBLIC }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install deps
        shell: bash
        run: |
          set -euo pipefail
          pip install --upgrade pip
          pip install playwright beautifulsoup4 lxml psycopg2-binary
          python -m playwright install --with-deps chromium

      # We avoid heredocs entirely to prevent YAML parse issues.
      - name: Verify scraper file exists
        shell: bash
        run: |
          set -euo pipefail
          if [[ ! -f scripts/rimi_crawl_categories_pw.py ]]; then
            echo "::error file=scripts/rimi_crawl_categories_pw.py::Scraper file not found. Commit scripts/rimi_crawl_categories_pw.py to the repo."
            exit 1
          fi
          python -m py_compile scripts/rimi_crawl_categories_pw.py
          chmod +x scripts/rimi_crawl_categories_pw.py

      - name: Prepare category list
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data
          if [[ -n "${{ github.event.inputs.categories_multiline }}" ]]; then
            printf "%s\n" "${{ github.event.inputs.categories_multiline }}" | tr -d '\r' | sed '/^[[:space:]]*$/d' > data/rimi_categories.txt
            echo "Using categories from input."
          elif [[ -f data/rimi_categories.txt ]]; then
            echo "Using repo file data/rimi_categories.txt"
          else
            # Minimal default without heredoc
            printf '%s\n' 'https://www.rimi.ee/epood/ee/tooted/leivad-saiad-kondiitritooted' > data/rimi_categories.txt
            echo "Using built-in sample category."
          fi
          echo "First few categories:"
          nl -ba data/rimi_categories.txt | sed -n '1,10p'

      - name: Run scraper
        shell: bash
        run: |
          set -euo pipefail
          python scripts/rimi_crawl_categories_pw.py \
            --cats-file data/rimi_categories.txt \
            --page-limit "${{ github.event.inputs.page_limit }}" \
            --max-products "${{ github.event.inputs.max_products }}" \
            --headless "${{ github.event.inputs.headless }}" \
            --req-delay "${{ github.event.inputs.req_delay }}"

      - name: Show CSV head
        shell: bash
        run: |
          head -n 20 rimi_products.csv || true

      - name: Upload CSV artifact
        uses: actions/upload-artifact@v4
        with:
          name: rimi_products.csv
          path: rimi_products.csv
          if-no-files-found: error
          retention-days: 7
