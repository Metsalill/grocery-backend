name: "Selver Category Crawl"

on:
  workflow_dispatch:
    inputs:
      click_products:
        description: "Click into PDPs (1) vs direct links (0)"
        required: false
        default: "1"
      page_limit:
        description: "Max pages per category (0 = all)"
        required: false
        default: "0"
      log_console:
        description: "Page console logging (0 | warn | all)"
        required: false
        default: "warn"
      req_delay:
        description: "Seconds between steps"
        required: false
        default: "0.6"
  # Nightly at 02:00 UTC
  schedule:
    - cron: "0 2 * * *"

concurrency:
  group: ${{ github.event_name == 'workflow_dispatch' && format('selver-category-crawl-{0}', github.run_id) || 'selver-category-crawl' }}
  cancel-in-progress: true

jobs:
  crawl-and-upsert:
    name: crawl-and-upsert (shard ${{ matrix.shard }})
    runs-on: ubuntu-latest
    timeout-minutes: 90
    strategy:
      fail-fast: false
      matrix:
        shard: [0, 1]
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL_PUBLIC }}
      SHARD: ${{ matrix.shard }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements-scraper.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install deps (crawler + Playwright)
        run: |
          pip install -r requirements-scraper.txt || pip install aiohttp beautifulsoup4 lxml asyncpg pg8000 psycopg2-binary playwright
          python -m playwright install --with-deps chromium

      - name: Prepare workspace
        run: mkdir -p data

      - name: Build shard slice (cover all categories this run; shard ${{ matrix.shard }})
        shell: bash
        env:
          SHARDS: 2
        run: |
          set -euo pipefail
          cp -f data/selver_categories.txt data/selver_categories_all.txt
          TOTAL=$(wc -l < data/selver_categories_all.txt)
          : "${SHARD:?SHARD env is required}"
          awk -v s="$SHARD" -v n="$SHARDS" 'NR>0 { if ((NR-1)%n==s) print }' \
            data/selver_categories_all.txt > data/selver_categories.txt
          echo "TOTAL categories: $TOTAL"
          echo "Sharding: SHARD=$SHARD / SHARDS=$SHARDS"
          echo "Slice count: $(wc -l < data/selver_categories.txt)"
          head -n 8 data/selver_categories.txt || true

      - name: Crawl Selver categories (Playwright)
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
          OUTPUT_CSV: data/selver.csv
          REQ_DELAY: ${{ github.event_name == 'workflow_dispatch' && inputs.req_delay || '0.6' }}
          PAGE_LIMIT: ${{ github.event_name == 'workflow_dispatch' && inputs.page_limit || '0' }}
          CATEGORIES_FILE: data/selver_categories.txt
          ALLOWLIST_ONLY: "1"
          USE_ROUTER: "1"
          CLICK_PRODUCTS: ${{ github.event_name == 'workflow_dispatch' && inputs.click_products || '1' }}
          LOG_CONSOLE: ${{ github.event_name == 'workflow_dispatch' && inputs.log_console || 'warn' }}
          NAV_TIMEOUT_MS: "60000"
          PRELOAD_DB: "1"
          PRELOAD_DB_QUERY: |
            SELECT DISTINCT ext_id
            FROM (
              SELECT sp.ext_id
                FROM public.staging_selver_products sp
               WHERE COALESCE(sp.ean_norm,'') <> ''
              UNION
              SELECT c.ext_id
                FROM public.selver_candidates c
               WHERE COALESCE(c.ean_norm,'') <> ''
              UNION
              SELECT m.ext_id
                FROM public.ext_product_map m
            ) u
            WHERE ext_id IS NOT NULL AND ext_id <> ''
          PGSSLMODE: "require"
        run: |
          set -euo pipefail
          set -x
          echo "::group::Runtime info"
          python --version
          echo "Start (UTC): $(date -u)"
          echo "::endgroup::"
          set +e
          set +o pipefail
          stdbuf -oL -eL timeout -k 60s 55m python -u scripts/selver_crawl_categories_pw.py \
            > >(tee data/selver_run.log) 2>data/selver_run.err
          status=${PIPESTATUS[0]}
          set -o pipefail
          set -e
          echo "End (UTC): $(date -u) — crawler exit code: ${status}"
          echo "::group::Crawler outputs"
          ls -lah data || true
          [ -f data/selver.csv ] && { echo "CSV size:"; wc -l data/selver.csv; du -h data/selver.csv; } || echo "CSV not found"
          [ -f data/selver_run.log ] && { echo "Log size:"; du -h data/selver_run.log; } || echo "Log not found"
          [ -s data/selver_run.err ] && { echo "---- stderr tail ----"; tail -n 120 data/selver_run.err; } || true
          echo "::endgroup::"
          if [ "${status}" -eq 124 ]; then
            echo "::warning::Crawler hit the time budget (timeout). Continuing with partial results."
          elif [ "${status}" -ne 0 ]; then
            echo "::warning::Crawler exited non-zero (${status}); continuing"
          fi

      - name: Dump crawler log (tail)
        if: always()
        run: |
          echo "----- last 300 lines of data/selver_run.log -----"
          if [ -f data/selver_run.log ]; then
            tail -n 300 data/selver_run.log
          else
            echo "(no log found)"
          fi

      - name: Install psql client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: DB sanity (connection + prices shape)
        shell: bash
        run: |
          set -euo pipefail
          psql "$DATABASE_URL" -c "\conninfo"
          psql "$DATABASE_URL" -c "SELECT current_database(), current_user, inet_server_addr(), inet_server_port();"
          psql "$DATABASE_URL" -c "\d prices" || true

      - name: Show CSV head (debug)
        if: always()
        run: |
          set -euo pipefail
          ls -l data || true
          echo "---- line count ----"
          wc -l data/selver.csv || true
          echo "---- first 10 lines ----"
          head -n 10 data/selver.csv || true
          if [ ! -s data/selver.csv ] && [ -s data/selver-sample.csv ]; then
            echo "Crawl produced no rows; using data/selver-sample.csv as fallback."
            cp -f data/selver-sample.csv data/selver.csv
          fi

      - name: Upload crawl artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: selver-crawl-shard-${{ matrix.shard }}-${{ github.run_id }}
          path: |
            data/selver.csv
            data/selver_run.log
            data/selver_run.err
            data/selver_debug/**/*.png
          if-no-files-found: warn
          retention-days: 7

      - name: Prepare DB (staging & helper tables)
        shell: bash
        run: |
          set -euo pipefail
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 <<'SQL'
          BEGIN;

          -- Staging with brand support
          CREATE TABLE IF NOT EXISTS public.staging_selver_products (
            ext_id        text PRIMARY KEY,
            name          text NOT NULL,
            brand         text,
            ean_raw       text,
            sku_raw       text,
            ean_norm      text GENERATED ALWAYS AS (regexp_replace(COALESCE(ean_raw,''), '[^0-9]', '', 'g')) STORED,
            size_text     text,
            price         numeric(12,2) NOT NULL,
            currency      text DEFAULT 'EUR',
            category_path text,
            category_leaf text,
            collected_at  timestamptz DEFAULT now()
          );
          ALTER TABLE public.staging_selver_products
            ADD COLUMN IF NOT EXISTS brand text;

          CREATE EXTENSION IF NOT EXISTS pg_trgm;
          CREATE INDEX IF NOT EXISTS ix_selver_ean       ON public.staging_selver_products (ean_norm);
          CREATE INDEX IF NOT EXISTS ix_selver_name_trgm ON public.staging_selver_products USING gin (name gin_trgm_ops);

          -- Store
          INSERT INTO public.stores (name, chain, is_online)
          SELECT 'Selver e-Selver', 'Selver', TRUE
          WHERE NOT EXISTS (SELECT 1 FROM public.stores WHERE chain='Selver' AND is_online=TRUE);

          -- Candidates with brand
          CREATE TABLE IF NOT EXISTS public.selver_candidates (
            ext_id        text PRIMARY KEY,
            ean_norm      text,
            ean_raw       text,
            sku_raw       text,
            name          text,
            brand         text,
            size_text     text,
            price         numeric(12,2),
            currency      text,
            category_path text,
            category_leaf text,
            last_seen     timestamptz DEFAULT now()
          );
          ALTER TABLE public.selver_candidates
            ADD COLUMN IF NOT EXISTS brand text;

          -- Explicit mapping table (ext_id → product_id)
          CREATE TABLE IF NOT EXISTS public.ext_product_map (
            ext_id     text PRIMARY KEY,
            product_id int NOT NULL REFERENCES public.products(id)
          );

          COMMIT;

          -- Keep only most recent price per (product, store)
          DO $$
          BEGIN
            WITH ranked AS (
              SELECT id,
                     ROW_NUMBER() OVER (PARTITION BY store_id, product_id
                                        ORDER BY collected_at DESC, id DESC) rn
              FROM public.prices
            )
            DELETE FROM public.prices p
            USING ranked r
            WHERE p.id = r.id AND r.rn > 1;

            IF NOT EXISTS (
              SELECT 1 FROM pg_constraint c
              WHERE c.conrelid='public.prices'::regclass
                AND c.contype='u'
                AND c.conkey = ARRAY[
                  (SELECT attnum FROM pg_attribute WHERE attrelid='public.prices'::regclass AND attname='product_id'),
                  (SELECT attnum FROM pg_attribute WHERE attrelid='public.prices'::regclass AND attname='store_id')
                ]
            ) THEN
              ALTER TABLE public.prices
                ADD CONSTRAINT uq_prices_per_store UNIQUE (product_id, store_id);
            END IF;
          END$$;
          SQL

      - name: Load CSV, upsert (TEMP staging, shard-safe)
        shell: bash
        run: |
          set -euo pipefail

          if [ ! -s data/selver.csv ]; then
            echo "No rows in data/selver.csv — skipping."
            exit 0
          fi

          ROW_CT=$( (wc -l < data/selver.csv) 2>/dev/null || echo 0 )
          if [ "$ROW_CT" -le 6 ]; then
            echo "::warning::Too few rows in CSV ($ROW_CT). Skipping DB load this run."
            exit 0
          fi

          # Absolute path for psql \copy (meta-commands can't span lines)
          CSV_ABS="$(python - <<'PY'
import os
print(os.path.abspath('data/selver.csv'))
PY
)"
          echo "CSV_ABS: $CSV_ABS"

          # CSV header includes BRAND:
          # ext_id,source_url,name,brand,ean_raw,ean_norm,sku_raw,size_text,price,currency,category_path,category_leaf
          cat > /tmp/selver_load.sql <<'SQL'
\set ON_ERROR_STOP on
BEGIN;

CREATE TEMP TABLE tmp_staging_selver_products (
  ext_id        text,
  source_url    text,
  name          text,
  brand         text,
  ean_raw       text,
  ean_norm      text,
  sku_raw       text,
  size_text     text,
  price         numeric,
  currency      text,
  category_path text,
  category_leaf text
);

-- SINGLE-LINE \copy with absolute path
\copy tmp_staging_selver_products (ext_id,source_url,name,brand,ean_raw,ean_norm,sku_raw,size_text,price,currency,category_path,category_leaf) FROM '__CSV__' WITH (FORMAT csv, HEADER true)

DELETE FROM tmp_staging_selver_products
WHERE name ILIKE '%vabad ametikohad%';

WITH filtered AS (
  SELECT
    ext_id,
    source_url,
    name,
    NULLIF(brand,'') AS brand,
    ean_raw,
    NULLIF(regexp_replace(COALESCE(ean_norm, ean_raw, ''), '[^0-9]', '', 'g'),'') AS ean_norm,
    sku_raw,
    NULLIF(size_text,'') AS size_text,
    NULLIF(NULLIF(price::text,''),'0')::numeric AS price,
    COALESCE(NULLIF(currency,''),'EUR') AS currency,
    NULLIF(category_path,'') AS category_path,
    NULLIF(category_leaf,'') AS category_leaf
  FROM tmp_staging_selver_products
),

upsert_staging AS (
  INSERT INTO public.staging_selver_products (
    ext_id, name, brand, ean_raw, sku_raw, size_text, price, currency, category_path, category_leaf
  )
  SELECT f.ext_id, f.name, f.brand, COALESCE(NULLIF(f.ean_raw,''), f.ean_norm),
         f.sku_raw, f.size_text, f.price, f.currency, f.category_path, f.category_leaf
  FROM filtered f
  ON CONFLICT (ext_id) DO UPDATE SET
    name          = EXCLUDED.name,
    brand         = COALESCE(EXCLUDED.brand, public.staging_selver_products.brand),
    ean_raw       = EXCLUDED.ean_raw,
    sku_raw       = EXCLUDED.sku_raw,
    size_text     = EXCLUDED.size_text,
    price         = EXCLUDED.price,
    currency      = EXCLUDED.currency,
    category_path = EXCLUDED.category_path,
    category_leaf = EXCLUDED.category_leaf,
    collected_at  = now()
  RETURNING ext_id
),

joined AS (
  SELECT
    COALESCE(m.product_id, pe.product_id) AS product_id,
    f.price,
    f.currency,
    f.ext_id
  FROM filtered f
  LEFT JOIN public.product_eans    pe ON pe.ean_norm = f.ean_norm AND f.ean_norm <> ''
  LEFT JOIN public.ext_product_map m  ON m.ext_id   = f.ext_id
  WHERE COALESCE(m.product_id, pe.product_id) IS NOT NULL
),
pick_one AS (
  SELECT DISTINCT ON (product_id)
         product_id, price, currency, ext_id
  FROM joined
  ORDER BY product_id, price ASC, ext_id DESC
)
INSERT INTO public.prices (store_id, product_id, price, currency, collected_at, source_url, source)
SELECT
  (SELECT id FROM public.stores WHERE chain='Selver' AND is_online=TRUE ORDER BY id LIMIT 1),
  p.product_id,
  p.price,
  p.currency,
  now(),
  p.ext_id,
  'online'
FROM pick_one p
ON CONFLICT (product_id, store_id) DO UPDATE
  SET price        = EXCLUDED.price,
      currency     = EXCLUDED.currency,
      collected_at = EXCLUDED.collected_at,
      source_url   = EXCLUDED.source_url,
      source       = EXCLUDED.source;

WITH filtered AS (
  SELECT * FROM (
    SELECT
      ext_id, source_url, name, brand, ean_raw,
      NULLIF(regexp_replace(COALESCE(ean_norm, ean_raw, ''), '[^0-9]', '', 'g'),'') AS ean_norm,
      sku_raw, size_text, price, currency, category_path, category_leaf
    FROM tmp_staging_selver_products
  ) q
),
missing AS (
  SELECT f.*
  FROM filtered f
  LEFT JOIN public.product_eans    pe ON pe.ean_norm = f.ean_norm AND f.ean_norm <> ''
  LEFT JOIN public.ext_product_map m  ON m.ext_id   = f.ext_id
  WHERE pe.product_id IS NULL AND m.product_id IS NULL
)
INSERT INTO public.selver_candidates
  (ext_id, ean_norm, ean_raw, sku_raw, name, brand, size_text, price, currency, category_path, category_leaf, last_seen)
SELECT
  ext_id, NULLIF(ean_norm,''), ean_raw, sku_raw, name, brand, size_text, price, currency, category_path, category_leaf, now()
FROM missing
ON CONFLICT (ext_id) DO UPDATE
  SET price         = EXCLUDED.price,
      currency      = EXCLUDED.currency,
      size_text     = COALESCE(EXCLUDED.size_text, public.selver_candidates.size_text),
      category_path = COALESCE(EXCLUDED.category_path, public.selver_candidates.category_path),
      category_leaf = COALESCE(EXCLUDED.category_leaf, public.selver_candidates.category_leaf),
      ean_raw       = COALESCE(EXCLUDED.ean_raw, public.selver_candidates.ean_raw),
      ean_norm      = COALESCE(EXCLUDED.ean_norm, public.selver_candidates.ean_norm),
      sku_raw       = COALESCE(EXCLUDED.sku_raw, public.selver_candidates.sku_raw),
      brand         = COALESCE(EXCLUDED.brand, public.selver_candidates.brand),
      last_seen     = now();

SELECT
  (SELECT COUNT(*) FROM tmp_staging_selver_products) AS staged_rows,
  (SELECT COUNT(*) FROM public.selver_candidates)    AS candidates_total;

COMMIT;
SQL

          # inject CSV absolute path & run
          sed -i "s|__CSV__|$CSV_ABS|g" /tmp/selver_load.sql
          psql "$DATABASE_URL" -f /tmp/selver_load.sql

      - name: Adopt Selver candidates with EANs (make products + prices)
        shell: bash
        env:
          PGSSLMODE: require
        run: |
          set -euo pipefail
          cat > /tmp/adopt_selver.sql <<'SQL'
          SET LOCAL statement_timeout = '25s';
          SET LOCAL lock_timeout = '5s';
          SET LOCAL idle_in_transaction_session_timeout = '30s';

          DO $do$
          DECLARE r record;
          BEGIN
            IF EXISTS (SELECT 1 FROM pg_proc WHERE proname='adopt_all_selver_candidates_with_ean') THEN
              PERFORM public.adopt_all_selver_candidates_with_ean();
            ELSIF EXISTS (SELECT 1 FROM pg_proc WHERE proname='adopt_candidate_with_ean') THEN
              FOR r IN
                SELECT ext_id FROM public.selver_candidates
                WHERE COALESCE(ean_norm,'') <> ''
              LOOP
                PERFORM public.adopt_candidate_with_ean(r.ext_id);
              END LOOP;
            END IF;
          END
          $do$;

          SELECT
            (SELECT COUNT(*) FROM public.selver_candidates) AS candidates_after,
            (SELECT COUNT(*) FROM public.prices p
               JOIN public.stores s ON s.id = p.store_id
              WHERE s.chain='Selver' AND s.is_online=TRUE) AS selver_online_prices;
          SQL

          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -f /tmp/adopt_selver.sql
