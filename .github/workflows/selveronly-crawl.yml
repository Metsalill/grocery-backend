name: "Selver Category Crawl (food)"

on:
  workflow_dispatch:
    inputs:
      click_products:
        description: "Click into PDPs (1) vs direct links (0)"
        required: false
        default: "0"
      page_limit:
        description: "Max pages per category (0 = all)"
        required: false
        default: "0"
      log_console:
        description: "Page console logging (0 | warn | all)"
        required: false
        default: "0"
      req_delay:
        description: "Seconds between steps"
        required: false
        default: "0.6"
  schedule:
    # Every 1.5 hours (90 min): 00:00, 01:30, 03:00, 04:30, ...
    - cron: "0 */3 * * *"        # 00:00, 03:00, 06:00, ...
    - cron: "30 1-23/3 * * *"    # 01:30, 04:30, 07:30, ...

concurrency:
  group: ${{ github.event_name == 'workflow_dispatch' && format('selver-category-crawl-{0}', github.run_id) || 'selver-category-crawl' }}
  cancel-in-progress: true

jobs:
  crawl-and-upsert:
    name: crawl-and-upsert (shard ${{ matrix.shard }})
    runs-on: ubuntu-latest
    timeout-minutes: 60
    strategy:
      fail-fast: false
      matrix:
        shard: [0, 1]   # run two slices in parallel each trigger
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL_PUBLIC }}
      SHARD: ${{ matrix.shard }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements-scraper.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install deps (crawler + Playwright)
        run: |
          pip install -r requirements-scraper.txt || pip install aiohttp beautifulsoup4 lxml asyncpg playwright
          python -m playwright install --with-deps chromium

      - name: Prepare workspace
        run: mkdir -p data

      # Rotate categories; shard 0 processes SLOT, shard 1 processes SLOT+1 (with fallback if tiny)
      - name: Build rotating category slice (90-min slots; shard ${{ matrix.shard }})
        shell: bash
        run: |
          set -euo pipefail
          cp -f data/selver_categories.txt data/selver_categories_all.txt

          TOTAL=$(wc -l < data/selver_categories_all.txt)
          SLOTS=16  # 24h / 1.5h
          BASE_SLOT=$(( ( $(date -u +%s) / 60 / 90 ) % SLOTS ))
          SLOT=$(( (BASE_SLOT + ${SHARD}) % SLOTS ))
          CHUNK=$(( (TOTAL + SLOTS - 1) / SLOTS ))  # ceil
          START=$(( SLOT*CHUNK + 1 ))
          END=$(( START + CHUNK - 1 ))
          [ "$END" -gt "$TOTAL" ] && END=$TOTAL

          sed -n "${START},${END}p" data/selver_categories_all.txt > data/selver_categories.txt

          # Fallback: if slice is too small, append the next chunk so we always have work
          SLICE_CT=$(wc -l < data/selver_categories.txt)
          if [ "$SLICE_CT" -lt 5 ]; then
            NEXT_START=$(( END + 1 ))
            NEXT_END=$(( NEXT_START + CHUNK - 1 ))
            if [ "$NEXT_START" -le "$TOTAL" ]; then
              sed -n "${NEXT_START},${NEXT_END}p" data/selver_categories_all.txt >> data/selver_categories.txt
            fi
          fi

          echo "TOTAL categories: $TOTAL"
          echo "BASE_SLOT: $BASE_SLOT ; SHARD: ${SHARD} ; EFFECTIVE SLOT: $SLOT / $SLOTS"
          echo "Slice lines: ${START}..${END}  (count: $(wc -l < data/selver_categories.txt))"
          head -n 5 data/selver_categories.txt || true

      - name: Crawl Selver categories (Playwright)
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
          OUTPUT_CSV: data/selver.csv
          REQ_DELAY: ${{ github.event_name == 'workflow_dispatch' && inputs.req_delay || '0.6' }}
          PAGE_LIMIT: ${{ github.event_name == 'workflow_dispatch' && inputs.page_limit || '0' }}
          CATEGORIES_FILE: data/selver_categories.txt
          ALLOWLIST_ONLY: "1"
          USE_ROUTER: "1"
          CLICK_PRODUCTS: ${{ github.event_name == 'workflow_dispatch' && inputs.click_products || '0' }}
          LOG_CONSOLE: ${{ github.event_name == 'workflow_dispatch' && inputs.log_console || '0' }}
        run: |
          set -euo pipefail
          set -x
          echo "::group::Runtime info"
          python --version
          echo "Start (UTC): $(date -u)"
          echo "::endgroup::"

          set +e
          set +o pipefail
          # Give crawler ~50 minutes of the 60-minute job window; split stderr to a separate file
          stdbuf -oL -eL timeout -k 60s 50m python -u scripts/selver_crawl_categories_pw.py \
            > >(tee data/selver_run.log) 2>data/selver_run.err
          status=${PIPESTATUS[0]}
          set -o pipefail
          set -e

          echo "End (UTC): $(date -u) — crawler exit code: ${status}"

          echo "::group::Crawler outputs"
          ls -lah data || true
          [ -f data/selver.csv ] && { echo "CSV size:"; wc -l data/selver.csv; du -h data/selver.csv; } || echo "CSV not found"
          [ -f data/selver_run.log ] && { echo "Log size:"; du -h data/selver_run.log; } || echo "Log not found"
          [ -s data/selver_run.err ] && { echo "---- stderr tail ----"; tail -n 120 data/selver_run.err; } || true
          echo "::endgroup::"

          if [ "${status}" -eq 124 ]; then
            echo "::warning::Crawler hit the time budget (timeout 50m). Continuing with partial results."
          elif [ "${status}" -ne 0 ]; then
            echo "::warning::Crawler exited non-zero (${status}); continuing"
          fi

      - name: Dump crawler log (tail)
        if: always()
        run: |
          echo "----- last 300 lines of data/selver_run.log -----"
          if [ -f data/selver_run.log ]; then
            tail -n 300 data/selver_run.log
          else
            echo "(no log found)"
          fi

      - name: Install psql client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: DB sanity (connection + prices shape)
        shell: bash
        run: |
          set -euo pipefail
          psql "$DATABASE_URL" -c "\conninfo"
          psql "$DATABASE_URL" -c "SELECT current_database(), current_user, inet_server_addr(), inet_server_port();"
          psql "$DATABASE_URL" -c "\d prices" || true

      - name: Show CSV head (debug)
        if: always()
        run: |
          set -euo pipefail
          ls -l data || true
          echo "---- line count ----"
          wc -l data/selver.csv || true
          echo "---- first 10 lines ----"
          head -n 10 data/selver.csv || true
          if [ ! -s data/selver.csv ] && [ -s data/selver-sample.csv ]; then
            echo "Crawl produced no rows; using data/selver-sample.csv as fallback."
            cp -f data/selver-sample.csv data/selver.csv
          fi

      - name: Upload crawl artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: selver-crawl-shard-${{ matrix.shard }}-${{ github.run_id }}
          path: |
            data/selver.csv
            data/selver_run.log
            data/selver_run.err
            data/selver_debug/**/*.png
          if-no-files-found: warn
          retention-days: 7

      - name: Prepare DB (staging & helper tables)
        shell: bash
        run: |
          set -euo pipefail
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 <<'SQL'
          BEGIN;

          -- Raw staging for selver CSV
          CREATE TABLE IF NOT EXISTS public.staging_selver_products (
            ext_id        text PRIMARY KEY,
            name          text NOT NULL,
            ean_raw       text,
            sku_raw       text,
            ean_norm      text GENERATED ALWAYS AS (regexp_replace(COALESCE(ean_raw,''), '\D','','g')) STORED,
            size_text     text,
            price         numeric(12,2) NOT NULL,
            currency      text DEFAULT 'EUR',
            category_path text,
            category_leaf text,
            collected_at  timestamptz DEFAULT now()
          );

          CREATE INDEX IF NOT EXISTS ix_selver_ean       ON public.staging_selver_products (ean_norm);
          CREATE INDEX IF NOT EXISTS ix_selver_name_trgm ON public.staging_selver_products USING gin (name gin_trgm_ops);

          -- Ensure one store row for Selver e-shop exists
          INSERT INTO public.stores (name, chain)
          SELECT 'Selver e-pood', 'Selver'
          WHERE NOT EXISTS (SELECT 1 FROM public.stores WHERE name='Selver e-pood' AND chain='Selver');

          -- Keep unmatched EANs for manual triage
          CREATE TABLE IF NOT EXISTS public.selver_candidates (
            ext_id        text PRIMARY KEY,
            ean_norm      text,
            ean_raw       text,
            sku_raw       text,
            name          text,
            size_text     text,
            price         numeric(12,2),
            currency      text,
            category_path text,
            category_leaf text,
            last_seen     timestamptz DEFAULT now()
          );

          COMMIT;

          -- Drop any single-column unique on prices(product_id) and any duplicate pair uniques
          DO $$
          DECLARE
            con_name text;
          BEGIN
            -- Drop unique constraints that are ONLY on (product_id)
            FOR con_name IN
              SELECT c.conname
              FROM pg_constraint c
              WHERE c.conrelid = 'public.prices'::regclass
                AND c.contype  = 'u'
                AND c.conkey   = ARRAY[
                  (SELECT attnum FROM pg_attribute
                   WHERE attrelid='public.prices'::regclass AND attname='product_id')
                ]
            LOOP
              EXECUTE format('ALTER TABLE public.prices DROP CONSTRAINT %I', con_name);
            END LOOP;

            -- Deduplicate rows on (store_id, product_id) before enforcing unique
            WITH ranked AS (
              SELECT id,
                     ROW_NUMBER() OVER (PARTITION BY store_id, product_id
                                        ORDER BY collected_at DESC, id DESC) rn
              FROM public.prices
            )
            DELETE FROM public.prices p
            USING ranked r
            WHERE p.id = r.id AND r.rn > 1;

            -- Ensure there is SOME unique on exactly (product_id, store_id), regardless of name or order.
            IF NOT EXISTS (
              SELECT 1
              FROM pg_constraint c
              WHERE c.conrelid = 'public.prices'::regclass
                AND c.contype  = 'u'
                AND (
                  c.conkey = ARRAY[
                    (SELECT attnum FROM pg_attribute WHERE attrelid='public.prices'::regclass AND attname='product_id'),
                    (SELECT attnum FROM pg_attribute WHERE attrelid='public.prices'::regclass AND attname='store_id')
                  ]
                  OR
                  c.conkey = ARRAY[
                    (SELECT attnum FROM pg_attribute WHERE attrelid='public.prices'::regclass AND attname='store_id'),
                    (SELECT attnum FROM pg_attribute WHERE attrelid='public.prices'::regclass AND attname='product_id')
                  ]
                )
            ) THEN
              ALTER TABLE public.prices
                ADD CONSTRAINT uq_prices_per_store UNIQUE (product_id, store_id);
            END IF;
          END$$;

          TRUNCATE TABLE public.staging_selver_products;
          SQL

      - name: Load CSV into staging & upsert
        shell: bash
        run: |
          set -euo pipefail

          if [ ! -s data/selver.csv ]; then
            echo "No rows in data/selver.csv — skipping load."
            exit 0
          fi

          # Guard: skip obviously bad/tiny runs (header + <=5 lines)
          ROW_CT=$( (wc -l < data/selver.csv) 2>/dev/null || echo 0 )
          if [ "$ROW_CT" -le 6 ]; then
            echo "::warning::Too few rows in CSV ($ROW_CT). Skipping DB load this run."
            exit 0
          fi

          # Adjust columns here if your CSV changes
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c \
            "\copy public.staging_selver_products (ext_id,name,ean_raw,sku_raw,size_text,price,currency,category_path,category_leaf) FROM 'data/selver.csv' CSV HEADER"

          # Insert/Update prices using composite key (product_id, store_id)
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 <<'SQL'
          WITH banned(kw) AS ( VALUES
            ('sisustus'),('kodutekstiil'),('valgustus'),('kardin'),('jouluvalgustid'),
            ('vaikesed-sisustuskaubad'),('kuunlad'),('kook-ja-lauakatmine'),
            ('uhekordsed-noud'),('kirja-ja-kontoritarbed'),('remondi-ja-turvatooted'),
            ('kulmutus-ja-kokkamisvahendid'),('omblus-ja-kasitootarbed'),('meisterdamine'),
            ('ajakirjad'),('autojuhtimine'),('kotid'),('aed-ja-lilled'),('lemmikloom'),
            ('sport'),('pallimangud'),('jalgrattasoit'),('ujumine'),('matkamine'),
            ('tervisesport'),('manguasjad'),('lutid'),('lapsehooldus'),('ideed-ja-hooajad'),
            ('kodumasinad'),('elektroonika'),('meelelahutuselektroonika'),
            ('vaikesed-kodumasinad'),('lambid-patareid-ja-taskulambid'),
            ('ilu-ja-tervis'),('kosmeetika'),('meigitooted'),('hugieen'),
            ('loodustooted-ja-toidulisandid')
          ),
          filtered AS (
            SELECT st.* FROM public.staging_selver_products st
            WHERE st.ext_id LIKE 'https://www.selver.ee/e/%'
              AND NOT EXISTS (
                SELECT 1 FROM banned
                WHERE lower(COALESCE(st.category_path,'') || ' ' ||
                            COALESCE(st.category_leaf,'') || ' ' ||
                            COALESCE(st.name,'')) LIKE '%' || banned.kw || '%'
              )
          ),
          joined AS (
            SELECT
              pe.product_id,
              f.price,
              f.currency,
              f.collected_at,
              f.ext_id
            FROM filtered f
            JOIN public.product_eans pe ON pe.ean_norm = f.ean_norm
          ),
          pick_one AS (
            SELECT DISTINCT ON (product_id)
                   product_id, price, currency
            FROM joined
            ORDER BY product_id,
                     collected_at DESC NULLS LAST,
                     price ASC,
                     ext_id DESC
          )
          INSERT INTO public.prices (store_id, product_id, price, currency, collected_at, source_url)
          SELECT
            (SELECT id FROM public.stores WHERE name='Selver e-pood' AND chain='Selver'),
            p.product_id,
            p.price,
            p.currency,
            NOW(),
            p.ext_id
          FROM pick_one p
          ON CONFLICT (product_id, store_id) DO UPDATE
            SET price        = EXCLUDED.price,
                currency     = EXCLUDED.currency,
                collected_at = EXCLUDED.collected_at,
                source_url   = EXCLUDED.source_url;
          SQL

          # Store unmatched rows for triage
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 <<'SQL'
          WITH banned(kw) AS ( VALUES
            ('sisustus'),('kodutekstiil'),('valgustus'),('kardin'),('jouluvalgustid'),
            ('vaikesed-sisustuskaubad'),('kuunlad'),('kook-ja-lauakatmine'),
            ('uhekordsed-noud'),('kirja-ja-kontoritarbed'),('remondi-ja-turvatooted'),
            ('kulmutus-ja-kokkamisvahendid'),('omblus-ja-kasitootarbed'),('meisterdamine'),
            ('ajakirjad'),('autojuhtimine'),('kotid'),('aed-ja-lilled'),('lemmikloom'),
            ('sport'),('pallimangud'),('jalgrattasoit'),('ujumine'),('matkamine'),
            ('tervisesport'),('manguasjad'),('lutid'),('lapsehooldus'),('ideed-ja-hooajad'),
            ('kodumasinad'),('elektroonika'),('meelelahutuselektroonika'),
            ('vaikesed-kodumasinad'),('lambid-patareid-ja-taskulambid'),
            ('ilu-ja-tervis'),('kosmeetika'),('meigitooted'),('hugieen'),
            ('loodustooted-ja-toidulisandid')
          ),
          filtered AS (
            SELECT st.* FROM public.staging_selver_products st
            WHERE st.ext_id LIKE 'https://www.selver.ee/e/%'
              AND NOT EXISTS (
                SELECT 1 FROM banned
                WHERE lower(COALESCE(st.category_path,'') || ' ' ||
                            COALESCE(st.category_leaf,'') || ' ' ||
                            COALESCE(st.name,'')) LIKE '%' || banned.kw || '%'
              )
          )
          INSERT INTO public.selver_candidates
            (ext_id, ean_norm, ean_raw, sku_raw, name, size_text, price, currency, category_path, category_leaf)
          SELECT
            f.ext_id, f.ean_norm, f.ean_raw, f.sku_raw, f.name, f.size_text, f.price, f.currency, f.category_path, f.category_leaf
          FROM filtered f
          LEFT JOIN public.product_eans pe ON pe.ean_norm = f.ean_norm
          WHERE pe.product_id IS NULL
          ON CONFLICT (ext_id) DO UPDATE
            SET price         = EXCLUDED.price,
                currency      = EXCLUDED.currency,
                size_text     = COALESCE(EXCLUDED.size_text, public.selver_candidates.size_text),
                category_path = COALESCE(EXCLUDED.category_path, public.selver_candidates.category_path),
                category_leaf = COALESCE(EXCLUDED.category_leaf, public.selver_candidates.category_leaf),
                ean_raw       = COALESCE(EXCLUDED.ean_raw, public.selver_candidates.ean_raw),
                sku_raw       = COALESCE(EXCLUDED.sku_raw, public.selver_candidates.sku_raw),
                last_seen     = now();

          SELECT
            (SELECT COUNT(*) FROM public.staging_selver_products) AS staged,
            (SELECT COUNT(*) FROM public.prices WHERE store_id=(SELECT id FROM public.stores WHERE name='Selver e-pood' AND chain='Selver')) AS price_rows,
            (SELECT COUNT(*) FROM public.selver_candidates) AS candidates;
          SQL
